
---

#  End-to-End MLOps Pipeline â€“ Sentiment Analysis Project

This repository implements a **complete end-to-end MLOps workflow** for **sentiment classification** using a **Logistic Regression model**.
It covers everything from **data ingestion â†’ model training â†’ evaluation â†’ model registry â†’ deployment â†’ monitoring**, all integrated with **MLflow, DVC, Docker, Kubernetes, and Prometheus**.

---

##  Project Overview

This project demonstrates how to:

* Version datasets and code using **DVC**
* Track experiments using **MLflow**
* Automatically register and promote models
* Serve models in production using **Flask + Gunicorn**
* Deploy on **Kubernetes**
* Monitor model and API metrics using **Prometheus**
* Generate developer documentation using **Sphinx**

---

## âš™ï¸ Tech Stack

| Category                | Tools / Frameworks                  |
| ----------------------- | ----------------------------------- |
| **Language**            | Python 3.11                         |
| **Data Versioning**     | DVC                                 |
| **Experiment Tracking** | MLflow + DAGsHub                    |
| **Modeling**            | Scikit-learn, NLTK                  |
| **Deployment**          | Flask, Gunicorn, Docker, Kubernetes |
| **Monitoring**          | Prometheus                          |
| **Documentation**       | Sphinx                              |
| **Cloud**               | AWS S3, ECR                         |
| **Code Quality**        | Flake8, Tox                         |
| **Automation**          | Makefile, setup.py                  |

---

##  Project Structure

```
.
â”œâ”€â”€ .dvc/                       # DVC metadata
â”œâ”€â”€ .github/                    # CI/CD workflows (if configured)
â”œâ”€â”€ docs/                       # Sphinx documentation
â”‚   â”œâ”€â”€ commands.rst
â”‚   â”œâ”€â”€ conf.py
â”‚   â”œâ”€â”€ getting-started.rst
â”‚   â”œâ”€â”€ index.rst
â”‚   â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ make.bat
â”‚
â”œâ”€â”€ flask_app/                  # Model serving API
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ load_model_test.py
â”‚   â”œâ”€â”€ preprocessing_utility.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”‚
â”œâ”€â”€ models/                     # Trained models and vectorizers
â”‚   â””â”€â”€ vectorizer.pkl
â”‚
â”œâ”€â”€ notebooks/                  # Experiments & analysis
â”‚   â”œâ”€â”€ data.csv
â”‚   â”œâ”€â”€ IMDB.csv
â”‚   â”œâ”€â”€ exp1.ipynb
â”‚   â”œâ”€â”€ exp2_bow_vs_tfidf.py
â”‚   â””â”€â”€ exp3_lor_bow_hp.py
â”‚
â”œâ”€â”€ references/                 # Reference documents / data schema
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ reports/                    # Reports and metrics
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ experiment_info.json
â”‚
â”œâ”€â”€ scripts/                    # Automation scripts
â”‚   â””â”€â”€ promote_model.py
â”‚
â”œâ”€â”€ src/                        # Core ML pipeline source code
â”‚   â”œâ”€â”€ connections/            # Database & S3 connectors
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ s3_connection.py
â”‚   â”‚   â””â”€â”€ ssms_connection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                   # Data ingestion and preprocessing
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â””â”€â”€ data_preprocessing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ features/               # Feature engineering scripts
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”‚
â”‚   â”œâ”€â”€ logger/                 # Logging setup
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ model/                  # Model building, evaluation, registry
â”‚       â”œâ”€â”€ model_building.py
â”‚       â”œâ”€â”€ model_evaluation.py
â”‚       â”œâ”€â”€ predict_model.py
â”‚       â””â”€â”€ register_model.py
â”‚
â”œâ”€â”€ tests/                      # Unit / integration tests
â”‚   â””â”€â”€ test_environment.py
â”‚
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ deployment.yaml             # Kubernetes Deployment + Service
â”œâ”€â”€ dvc.yaml                    # DVC pipeline definition
â”œâ”€â”€ dvc.lock
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ params.yaml                 # Pipeline parameters (test_size, etc.)
â”œâ”€â”€ projectflow.txt             # Visual project workflow
â”œâ”€â”€ README.md                   # 
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ test_environment.py
â””â”€â”€ tox.ini
```

---

##  MLOps Pipeline Stages

### **1ï¸âƒ£ Data Ingestion**

* Loads dataset from AWS S3 or CSV.
* Splits into train/test (based on `params.yaml`).
* Stores raw data under `data/raw/`.

### **2ï¸âƒ£ Data Preprocessing**

* Cleans and normalizes text:

  * Lowercasing
  * Removing punctuation, numbers, URLs
  * Stopword removal
  * Lemmatization
* Outputs processed data to `data/interim/`.

### **3ï¸âƒ£ Feature Engineering**

* Converts text to numerical features using **CountVectorizer (Bag of Words)**.
* Saves fitted vectorizer to `models/vectorizer.pkl`.
* Stores processed features in `data/processed/`.

### **4ï¸âƒ£ Model Building**

* Trains **Logistic Regression** on the processed dataset.
* Saves trained model to `models/model.pkl`.

### **5ï¸âƒ£ Model Evaluation**

* Evaluates metrics: Accuracy, Precision, Recall, AUC.
* Logs metrics and parameters to **MLflow**.
* Saves results in `reports/metrics.json` and `reports/experiment_info.json`.

### **6ï¸âƒ£ Model Registration & Promotion**

* Registers model in **MLflow Model Registry** via `register_model.py`.
* Promotes best-performing model to **Staging** or **Production** using `promote_model.py`.

### **7ï¸âƒ£ Deployment (Flask + Gunicorn + K8s)**

* Flask app (`flask_app/app.py`) serves predictions.
* Uses MLflowâ€™s **production model** via registry URI.
* Containerized using Docker â†’ deployed on **Kubernetes** with LoadBalancer.

### **8ï¸âƒ£ Monitoring (Prometheus Integration)**

* Tracks:

  * Total requests (`app_request_count`)
  * Latency (`app_request_latency_seconds`)
  * Prediction count by class (`model_prediction_count`)
* Metrics exposed at `/metrics`.

### **9ï¸âƒ£ Documentation (Sphinx)**

* Developer documentation stored in `/docs`.
* Build docs locally:

  ```bash
  sphinx-build -b html docs/ build/
  ```

---

## âš™ï¸ Configuration Files

| File              | Purpose                                    |
| ----------------- | ------------------------------------------ |
| `params.yaml`     | Hyperparameters & test split configuration |
| `dvc.yaml`        | DVC pipeline stage definitions             |
| `Dockerfile`      | Containerization for production            |
| `deployment.yaml` | Kubernetes deployment config               |
| `setup.py`        | Package configuration                      |
| `.flake8`         | Code quality rules                         |
| `tox.ini`         | Environment testing setup                  |
| `Makefile`        | Simplified pipeline commands               |
| `projectflow.txt` | Flow summary for visualization             |

---

##  MLflow + DAGsHub Setup

**Tracking URI:**

```
https://dagshub.com/vikashdas770/YT-Capstone-Project.mlflow
```

**Environment Variable:**

```bash
export CAPSTONE_TEST=<your_dagshub_token>
```

**MLflow Registered Model:**

* `my_model`
* Automatically transitions from **Staging â†’ Production** based on evaluation metrics.

---

##  Deployment Workflow

### Build Docker Image

```bash
docker build -t flask-app:latest .
```

### Run Locally

```bash
docker run -p 5000:5000 flask-app:latest
```

### Deploy to Kubernetes

```bash
kubectl apply -f deployment.yaml
```

### Access App

```
http://<external-ip>:5000
```

---

## ğŸ“ˆ Prometheus Metrics

| Metric                        | Description                                 |
| ----------------------------- | ------------------------------------------- |
| `app_request_count`           | Number of API requests by method & endpoint |
| `app_request_latency_seconds` | Request latency                             |
| `model_prediction_count`      | Predictions per sentiment class             |

Endpoint:

```
http://<pod-ip>:5000/metrics
```

---

##  Documentation

Sphinx-based project documentation:

```bash
cd docs
make html
```

Open:
`build/html/index.html`

---

##  Key Highlights

âœ” Fully modular DVC pipeline
âœ” MLflow + DAGsHub tracking
âœ” Automated model registry and promotion
âœ” Flask + Gunicorn deployment
âœ” Kubernetes orchestration
âœ” Prometheus monitoring
âœ” Auto-generated developer documentation
âœ” Production-grade structure with Makefile & CI-ready setup

---

